{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f230cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/08 15:03:41 WARN Utils: Your hostname, Ivans-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.20.218 instead (on interface en0)\n",
      "25/06/08 15:03:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'unittest'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m----> 3\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSpark SQL Example\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m spark\n",
      "File \u001b[0;32m~/Documents/repos/personal/data-engineering-exp/.venv/lib/python3.10/site-packages/pyspark/sql/session.py:556\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[1;32m    555\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[0;32m--> 556\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
      "File \u001b[0;32m~/Documents/repos/personal/data-engineering-exp/.venv/lib/python3.10/site-packages/pyspark/core/context.py:523\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 523\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[0;32m~/Documents/repos/personal/data-engineering-exp/.venv/lib/python3.10/site-packages/pyspark/core/context.py:207\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/repos/personal/data-engineering-exp/.venv/lib/python3.10/site-packages/pyspark/core/context.py:249\u001b[0m, in \u001b[0;36m_do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/repos/personal/data-engineering-exp/.venv/lib/python3.10/site-packages/pyspark/conf.py:136\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, loadDefaults, _jvm, _jconf)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# JVM is not created, so store data in self._conf first\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jconf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Documents/repos/personal/data-engineering-exp/.venv/lib/python3.10/site-packages/py4j/java_gateway.py:1613\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mUserHelpAutoCompletion\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m   1598\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m \u001b[38;5;124;03m    Type a package name or a class name.\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m \n\u001b[1;32m   1601\u001b[0m \u001b[38;5;124;03m    For example with a JVMView called view:\u001b[39;00m\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;124;03m    >>> o = view.Object() # create a java.lang.Object\u001b[39;00m\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;124;03m    >>> random = view.jvm.java.util.Random() # create a java.util.Random\u001b[39;00m\n\u001b[1;32m   1604\u001b[0m \n\u001b[1;32m   1605\u001b[0m \u001b[38;5;124;03m    The default JVMView is in the gateway and is called:\u001b[39;00m\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;124;03m    >>> gateway.jvm\u001b[39;00m\n\u001b[1;32m   1607\u001b[0m \n\u001b[1;32m   1608\u001b[0m \u001b[38;5;124;03m    By default, java.lang.* is available in the view. To\u001b[39;00m\n\u001b[1;32m   1609\u001b[0m \u001b[38;5;124;03m    add additional Classes/Packages, do:\u001b[39;00m\n\u001b[1;32m   1610\u001b[0m \u001b[38;5;124;03m    >>> from py4j.java_gateway import java_import\u001b[39;00m\n\u001b[1;32m   1611\u001b[0m \u001b[38;5;124;03m    >>> java_import(gateway.jvm, \"com.example.Class1\")\u001b[39;00m\n\u001b[1;32m   1612\u001b[0m \u001b[38;5;124;03m    >>> instance = gateway.jvm.Class1()\u001b[39;00m\n\u001b[0;32m-> 1613\u001b[0m \n\u001b[1;32m   1614\u001b[0m \u001b[38;5;124;03m    Package and class completions are only available for\u001b[39;00m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;124;03m    explicitly imported Java classes. For example, if you\u001b[39;00m\n\u001b[1;32m   1616\u001b[0m \u001b[38;5;124;03m    java_import(gateway.jvm, \"com.example.Class1\")\u001b[39;00m\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;124;03m    then Class1 will appear in the completions.\u001b[39;00m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m     KEY \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<package or class name>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/repos/personal/data-engineering-exp/.venv/lib/python3.10/site-packages/py4j/java_gateway.py:1598\u001b[0m, in \u001b[0;36m_get_args\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mUserHelpAutoCompletion\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[0;32m-> 1598\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m \u001b[38;5;124;03m    Type a package name or a class name.\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m \n\u001b[1;32m   1601\u001b[0m \u001b[38;5;124;03m    For example with a JVMView called view:\u001b[39;00m\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;124;03m    >>> o = view.Object() # create a java.lang.Object\u001b[39;00m\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;124;03m    >>> random = view.jvm.java.util.Random() # create a java.util.Random\u001b[39;00m\n\u001b[1;32m   1604\u001b[0m \n\u001b[1;32m   1605\u001b[0m \u001b[38;5;124;03m    The default JVMView is in the gateway and is called:\u001b[39;00m\n\u001b[1;32m   1606\u001b[0m \u001b[38;5;124;03m    >>> gateway.jvm\u001b[39;00m\n\u001b[1;32m   1607\u001b[0m \n\u001b[1;32m   1608\u001b[0m \u001b[38;5;124;03m    By default, java.lang.* is available in the view. To\u001b[39;00m\n\u001b[1;32m   1609\u001b[0m \u001b[38;5;124;03m    add additional Classes/Packages, do:\u001b[39;00m\n\u001b[1;32m   1610\u001b[0m \u001b[38;5;124;03m    >>> from py4j.java_gateway import java_import\u001b[39;00m\n\u001b[1;32m   1611\u001b[0m \u001b[38;5;124;03m    >>> java_import(gateway.jvm, \"com.example.Class1\")\u001b[39;00m\n\u001b[1;32m   1612\u001b[0m \u001b[38;5;124;03m    >>> instance = gateway.jvm.Class1()\u001b[39;00m\n\u001b[1;32m   1613\u001b[0m \n\u001b[1;32m   1614\u001b[0m \u001b[38;5;124;03m    Package and class completions are only available for\u001b[39;00m\n\u001b[1;32m   1615\u001b[0m \u001b[38;5;124;03m    explicitly imported Java classes. For example, if you\u001b[39;00m\n\u001b[1;32m   1616\u001b[0m \u001b[38;5;124;03m    java_import(gateway.jvm, \"com.example.Class1\")\u001b[39;00m\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;124;03m    then Class1 will appear in the completions.\u001b[39;00m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m     KEY \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<package or class name>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/repos/personal/data-engineering-exp/.venv/lib/python3.10/site-packages/pyspark/sql/types.py:3282\u001b[0m, in \u001b[0;36mcan_convert\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/Documents/repos/personal/data-engineering-exp/.venv/lib/python3.10/site-packages/pyspark/testing/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Licensed to the Apache Software Foundation (ASF) under one or more\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# contributor license agreements.  See the NOTICE file distributed with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m assertDataFrameEqual, assertSchemaEqual\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandasutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m assertPandasOnSparkEqual\n\u001b[1;32m     21\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massertDataFrameEqual\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massertSchemaEqual\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massertPandasOnSparkEqual\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/repos/personal/data-engineering-exp/.venv/lib/python3.10/site-packages/pyspark/testing/utils.py:22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstruct\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munittest\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdifflib\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m time, sleep\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'unittest'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Spark SQL Example\").getOrCreate()\n",
    "spark\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
